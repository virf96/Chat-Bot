{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOh33Id8lVSwyt0xF+qdEv0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/virf96/Chat-Bot/blob/master/ChatBot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0mL5oyktwDEJ",
        "colab_type": "text"
      },
      "source": [
        "# Proyecto NLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oA_y9PGufqN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "2b84ba72-588f-409d-f97d-589d88e6182f"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import string \n",
        "import random"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9F3qoT16NzC",
        "colab_type": "text"
      },
      "source": [
        "# Definimos el Corpus\n",
        "\n",
        "¿Que es el Corpus?\n",
        "\n",
        "Base de conocimiento, indica las preguntas frecuentes que podría preguntar el cliente"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYIGoJNLwTPD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "819ceb08-dec5-4600-9e31-8862deffbfae"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FWU31cdBaTl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f=open(\"/content/drive/My Drive/Prueba_ChatBot/corpus.txt\",'r',errors='ignore')\n",
        "raw=f.read()"
      ],
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2mm03JDLBkV",
        "colab_type": "text"
      },
      "source": [
        "Imprimimos la lectura del **Corpus (.txt)** en modo texto plano.\n",
        "\n",
        "Los puntos, signos de interrogación y caracteres espaciados serán los que utilicemos a la hora de partir las frases a devolver para el cliente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QoM5tWzFK9fC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "4b1c0023-130f-4791-96e2-d756dffbad0a"
      },
      "source": [
        "raw"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'sitemas se encuentra en el piso 7.\\n\\npuedes levantar una peticion llamando a la extension 561-221.\\n\\nel equipo de data analytics esta en cabezado por alberto.\\n\\nel hoario de atencin es de 8am-6:30pm\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhjHWrvRL3kY",
        "colab_type": "text"
      },
      "source": [
        "# Pre procesamiento del texto **Corpus**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pltsa0VXMV-n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "raw=raw.lower() #Convertimos a minúscula"
      ],
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RsvIIopMik_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "c3a40575-b8ae-444f-ef5f-cd27c476b433"
      },
      "source": [
        "raw"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'sitemas se encuentra en el piso 7.\\n\\npuedes levantar una peticion llamando a la extension 561-221.\\n\\nel equipo de data analytics esta en cabezado por alberto.\\n\\nel hoario de atencin es de 8am-6:30pm\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9q5DN_sJMn7P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "dc2ed581-edb4-4294-9ed3-6f32827d4190"
      },
      "source": [
        "#Tokenizamos en base a sentencias\n",
        "sent_tokens = nltk.sent_tokenize(raw)\n",
        "sent_tokens\n",
        "sent_tokens[1]"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'el hoario de atencin es de 8am-6:30pm'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0US6zFlN7Zg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "outputId": "a6fa209f-d275-499d-8ddf-2d74b371b81b"
      },
      "source": [
        "#Tokenizamos en base a palabras\n",
        "word_tokens = nltk.word_tokenize(raw)\n",
        "word_tokens"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['sitemas',\n",
              " 'se',\n",
              " 'encuentra',\n",
              " 'en',\n",
              " 'el',\n",
              " 'piso',\n",
              " '7.',\n",
              " 'puedes',\n",
              " 'levantar',\n",
              " 'una',\n",
              " 'peticion',\n",
              " 'llamando',\n",
              " 'a',\n",
              " 'la',\n",
              " 'extension',\n",
              " '561-221.',\n",
              " 'el',\n",
              " 'equipo',\n",
              " 'de',\n",
              " 'data',\n",
              " 'analytics',\n",
              " 'esta',\n",
              " 'en',\n",
              " 'cabezado',\n",
              " 'por',\n",
              " 'alberto',\n",
              " '.',\n",
              " 'el',\n",
              " 'hoario',\n",
              " 'de',\n",
              " 'atencin',\n",
              " 'es',\n",
              " 'de',\n",
              " '8am-6:30pm']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4-K99IzOXEH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Lematizador\n",
        "lemmer=nltk.stem.WordNetLemmatizer()\n",
        "\n",
        "#Función para lematizar uno a uno los wordtokens\n",
        "def LemTokens(tokens):\n",
        "  return [lemmer.lemmatize(token) for token in tokens]"
      ],
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPJgDdROPoqe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Removemos signos de puntuación\n",
        "remove_punct_dict = dict((ord(punct),None) for punct in string.punctuation)\n",
        "\n",
        "#Se le da un texto a la función y está le elimina los signos de puntuación y la tokeniza\n",
        "def LemNormalize(text):\n",
        "  return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))"
      ],
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JvhTs3JMWRY",
        "colab_type": "text"
      },
      "source": [
        "# Pre procesamiento del texto (Mensaje de usuario) \n",
        "\n",
        "#+\n",
        "\n",
        "#similitud del texto del usuario vs Corpus\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZOnJ6sNZLiO",
        "colab_type": "text"
      },
      "source": [
        "**CONSIDERACIONES:**\n",
        "\n",
        "A menudo dentro de un texto suelen dominar los **artículos** y **preposiciones**, por lo que todas esas palabras que no contienen la información base, se les dará un menor peso.\n",
        "\n",
        "<img src=\"https://seaprueba.com/wp-content/uploads/2019/09/Tipos-de-Art%C3%ADculos.png\">\n",
        "\n",
        "<img src=\"https://i.pinimg.com/originals/66/6b/e9/666be9803c3b850a02bec4f811bb7cc4.jpg\">\n",
        "\n",
        "Para esto usaremos la siguiente función:\n",
        "\n",
        "**TF-IDF:** Pondera las palabras que no aportan información relevante con un menor peso, tales como preposiciones o artículos que tienden a repetirse mucho. El resultado tras aplicarlo a un texto es un vector que indica la palabra o la oración.\n",
        "\n",
        "##¿Como evaluamos la similitud entre el mensaje del usuario y el Corpus?\n",
        "\n",
        "**Similitud de coseno:** Medida de similitud entre dos vectores distintos de cero. Se usará para encontrar similitud entre las palabras ingresadas por el usuario y las palabras del Corpus\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wL3qZqmoK-3O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from nltk.corpus import stopwords"
      ],
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9m_1R_RfkyOK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Función para determinar la similitud del texto insetado y el Corpus\n",
        "\n",
        "#Definimos función que como entrada tendrá el mensaje del usuario\n",
        "def response (user_response):\n",
        "  #Definimos la respuesta como vacía\n",
        "  robo_response=''\n",
        "  #Añadimos la respuesta del usuario al Corpus\n",
        "  sent_tokens.append(user_response)\n",
        "  #Como tokenizador utilizaremos la lematización que definimos e indicamos que el idioma es español\n",
        "  TfidfVec= TfidfVectorizer(tokenizer=LemNormalize, stop_words=stopwords.words('spanish'))\n",
        "  #Ajustamos en base al listado del sent_tokens (oraciones del corpus como mensaje de usuario)\n",
        "  tfidf = TfidfVec.fit_transform(sent_tokens)\n",
        "\n",
        "  #Evaluamos la similitud de coseno entre mensaje de usuario (tfidf[-1]) y el CORPUS (tfidf)\n",
        "\n",
        "  #Definimos función que no arrojara el resultado más aproximado entre el mensaje de usuario y el Corpus\n",
        "  vals = cosine_similarity(tfidf[-1],tfidf) #Similitud entre vector de entrada (usuario) vs vector(Corpus)\n",
        "  idx = vals.argsort()[0][-2]\n",
        "  flat = vals.flatten()\n",
        "  flat.sort()\n",
        "  req_tfidf = flat[-2]\n",
        "\n",
        "  if(req_tfidf==0):\n",
        "    #Si el resultado es cero, dira \"lo siento\"\n",
        "    robo_response = robo_response+\"Lo siento, no te he entendido. Si no puedo responder a lo que bucas contacta con Sistemas\"\n",
        "    return robo_response\n",
        "\n",
        "  else:\n",
        "    #En otro caso, nos devolvera la sentencia de tokens con el indice en donde obtuve la mayor similitud de coseno\n",
        "    robo_response = robo_response+sent_tokens[idx]\n",
        "    return robo_response\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQVg-20wtp8y",
        "colab_type": "text"
      },
      "source": [
        "# Coincidencias Manuales"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpFRL9v8nkCw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SALUDOS_INPUTS = (\"hola\",\"saludos\",\"qué tal\",\"buenos días\")\n",
        "SALUDOS_OUTPUTS = (\"Hola\",\"Hola, ¿Cómo te puedo ayudar?\",\"Hola, encantado de hablar contigo\",\"Hola, ¿Qué tal?\")\n",
        "\n",
        "#Definimos una función que como entrada tendrá un saludo\n",
        "def saludos(sentence):\n",
        "  #Cortamos la sentencia\n",
        "  for word in sentence.split():\n",
        "    #Convertimos todo a minusculas para poder hacer match con nuestros posibles inputs\n",
        "    if word.lower() in SALUDOS_INPUTS:\n",
        "      #Regresa un saludo tomado aleatoriamente\n",
        "      return random.choice(SALUDOS_OUTPUTS)\n"
      ],
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7G8LXkSqyZ9f",
        "colab_type": "text"
      },
      "source": [
        "#Generación de respuesta"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfVDB4hux8L9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "ab856359-1623-4d5e-d242-d91bd0049fe4"
      },
      "source": [
        "flag = True\n",
        "print(\"ROBOT: Mi nombre es ROBOT. Trataré de responder tus dudas, Si quieres salir, escribe 'salir\")\n",
        "while(flag==True):\n",
        "  user_response = input()\n",
        "  #Convertimos la entrada en minuscula para poder hacer match\n",
        "  user_response = user_response.lower() \n",
        "\n",
        "  if(user_response!='salir'):\n",
        "\n",
        "      if(user_response=='gracias' or user_response=='muchas gracias'):\n",
        "          flag=True\n",
        "          print(\"ROBOT: No hay de qué\")\n",
        "\n",
        "      else:\n",
        "          if(saludos(user_response)!=None): #Si la palabra insertada por el usuario es un saludo(coincidencias manuales definidas)\n",
        "            print(\"ROBOT: \"+saludos(user_response))\n",
        "\n",
        "          else: #Si la palabra insertada no es un saludo----> Query\n",
        "              print(\"ROBOT: \",end=\"\")\n",
        "              print(response(user_response))\n",
        "              sent_tokens.remove(user_response) #Eliminamos del corpus la respuesta del usuario\n",
        "\n",
        "              \n",
        "\n",
        "  else:\n",
        "      flag = False\n",
        "      print(\"Robot: Nos vemos pronto, ¡Cuidate!\")\n"
      ],
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ROBOT: Mi nombre es ROBOT. Trataré de responder tus dudas, Si quieres salir, escribe 'salir\n",
            "puto\n",
            "ROBOT: Lo siento, no te he entendido. Si no puedo responder a lo que bucas contacta con Sistemas\n",
            "hola\n",
            "ROBOT: Hola, encantado de hablar contigo\n",
            "salir\n",
            "Robot: Nos vemos pronto, ¡Cuidate!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5X-PxhD_HfXF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}